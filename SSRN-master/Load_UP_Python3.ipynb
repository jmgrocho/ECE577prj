{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished importing modules in *Load UP* at Fri May  3 01:35:01 2019\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.optimizers import Adam, SGD, Adadelta, RMSprop, Nadam\n",
    "import keras.callbacks as kcallbacks\n",
    "from keras.regularizers import l2\n",
    "import time\n",
    "import os\n",
    "from Utils import zeroPadding, normalization, doPCA, modelStatsRecord, averageAccuracy, ssrn_SS_UP\n",
    "\n",
    "import collections\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "print('Finished importing modules in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished indexToAssignment in *Load UP* at Fri May  3 01:35:02 2019\n"
     ]
    }
   ],
   "source": [
    "def indexToAssignment(index_, Row, Col, pad_length):\n",
    "    new_assign = {}\n",
    "    for counter, value in enumerate(index_):\n",
    "        assign_0 = value // Col + pad_length\n",
    "        assign_1 = value % Col + pad_length\n",
    "        new_assign[counter] = [assign_0, assign_1]\n",
    "    return new_assign\n",
    "\n",
    "print('Finished indexToAssignment in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assignmentToIndex in *Load UP* at Fri May  3 01:35:03 2019\n"
     ]
    }
   ],
   "source": [
    "def assignmentToIndex(assign_0, assign_1, Row, Col):\n",
    "    new_index = assign_0 * Col + assign_1\n",
    "    return new_index\n",
    "\n",
    "print('Finished assignmentToIndex in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished selectNeighboringPatch in *Load UP* at Fri May  3 01:35:04 2019\n"
     ]
    }
   ],
   "source": [
    "def selectNeighboringPatch(matrix, pos_row, pos_col, ex_len):\n",
    "    selected_rows = matrix[range(pos_row - ex_len, pos_row + ex_len + 1), :]\n",
    "    selected_patch = selected_rows[:, range(pos_col - ex_len, pos_col + ex_len + 1)]\n",
    "    return selected_patch\n",
    "\n",
    "print('Finished selectNeighboringPatch in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sampling in *Load UP* at Fri May  3 01:35:05 2019\n"
     ]
    }
   ],
   "source": [
    "def sampling(proptionVal, groundTruth):  # divide dataset into train and test datasets\n",
    "    labels_loc = {}\n",
    "    train = {}\n",
    "    test = {}\n",
    "    m = max(groundTruth)\n",
    "    for i in range(m):\n",
    "        indices = [j for j, x in enumerate(groundTruth.ravel().tolist()) if x == i + 1]\n",
    "        np.random.shuffle(indices)\n",
    "        labels_loc[i] = indices\n",
    "        nb_val = int(proptionVal * len(indices))\n",
    "        train[i] = indices[:-nb_val]\n",
    "        test[i] = indices[-nb_val:]\n",
    "    # whole_indices = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for i in range(m):\n",
    "        #        whole_indices += labels_loc[i]\n",
    "        train_indices += train[i]\n",
    "        test_indices += test[i]\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    return train_indices, test_indices\n",
    "\n",
    "print('Finished sampling in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sampling in *Load UP* at Fri May  3 01:35:06 2019\n"
     ]
    }
   ],
   "source": [
    "def res4_model_ss():\n",
    "    model_res4 = ssrn_SS_UP.ResnetBuilder.build_resnet_8((1, img_rows, img_cols, img_channels), nb_classes)\n",
    "\n",
    "    RMS = RMSprop(lr=0.0003)\n",
    "    # Let's train the model using RMSprop\n",
    "    model_res4.compile(loss='categorical_crossentropy', optimizer=RMS, metrics=['accuracy'])\n",
    "\n",
    "    return model_res4\n",
    "\n",
    "print('Finished sampling in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 340, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Iteration\n",
      "input shape: 103\n",
      "input shape: (None, 7, 7, 49, 24)\n",
      "conv_spc_result shape: (None, 7, 7, 1, 128)\n",
      "conv1 shape: (None, 5, 5, 1, 24)\n",
      "input shape: (None, 5, 5, 1, 24)\n",
      "3D RESNET_SS4 without BN training finished.\n",
      "# 1 Iteration\n",
      "Finished sampling in *Load UP* at Fri May  3 01:37:59 2019\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# uPavia = sio.loadmat(os.path.join(cwd, './datasets/UP/PaviaU.mat'))\n",
    "# gt_uPavia = sio.loadmat(os.path.join(cwd, './datasets/UP/PaviaU_gt.mat'))\n",
    "\n",
    "\n",
    "\n",
    "uPavia = sio.loadmat(r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/datasets/UP/PaviaU.mat''')\n",
    "gt_uPavia = sio.loadmat(r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/datasets/UP/PaviaU_gt.mat''')\n",
    "data_IN = uPavia['paviaU']\n",
    "gt_IN = gt_uPavia['paviaU_gt']\n",
    "print (data_IN.shape)\n",
    "\n",
    "# new_gt_IN = set_zeros(gt_IN, [1,4,7,9,13,15,16])\n",
    "new_gt_IN = gt_IN\n",
    "\n",
    "batch_size = 16\n",
    "nb_classes = 9\n",
    "nb_epoch = 200  # 400\n",
    "img_rows, img_cols = 7, 7  # 27, 27\n",
    "patience = 200\n",
    "\n",
    "INPUT_DIMENSION_CONV = 103\n",
    "INPUT_DIMENSION = 103\n",
    "\n",
    "# 10%:10%:80% data for training, validation and testing\n",
    "\n",
    "TOTAL_SIZE = 42776\n",
    "VAL_SIZE = 4281\n",
    "TRAIN_SIZE = 4281\n",
    "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "\n",
    "img_channels = 103\n",
    "VALIDATION_SPLIT = 0.90\n",
    "\n",
    "img_channels = 103\n",
    "PATCH_LENGTH = 3  # Patch_size (13*2+1)*(13*2+1)\n",
    "\n",
    "data = data_IN.reshape(np.prod(data_IN.shape[:2]), np.prod(data_IN.shape[2:]))\n",
    "gt = new_gt_IN.reshape(np.prod(new_gt_IN.shape[:2]), )\n",
    "\n",
    "data = preprocessing.scale(data)\n",
    "\n",
    "# scaler = preprocessing.MaxAbsScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "data_ = data.reshape(data_IN.shape[0], data_IN.shape[1], data_IN.shape[2])\n",
    "whole_data = data_\n",
    "padded_data = zeroPadding.zeroPadding_3D(whole_data, PATCH_LENGTH)\n",
    "\n",
    "ITER = 1\n",
    "CATEGORY = 9\n",
    "\n",
    "train_data = np.zeros((TRAIN_SIZE, 2 * PATCH_LENGTH + 1, 2 * PATCH_LENGTH + 1, INPUT_DIMENSION_CONV))\n",
    "test_data = np.zeros((TEST_SIZE, 2 * PATCH_LENGTH + 1, 2 * PATCH_LENGTH + 1, INPUT_DIMENSION_CONV))\n",
    "\n",
    "KAPPA_RES_SS4 = []\n",
    "OA_RES_SS4 = []\n",
    "AA_RES_SS4 = []\n",
    "TRAINING_TIME_RES_SS4 = []\n",
    "TESTING_TIME_RES_SS4 = []\n",
    "ELEMENT_ACC_RES_SS4 = np.zeros((ITER, CATEGORY))\n",
    "\n",
    "# seeds = [1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229]\n",
    "\n",
    "seeds = [1334]\n",
    "\n",
    "for index_iter in range(ITER):\n",
    "    print(\"# %d Iteration\" % (index_iter + 1))\n",
    "\n",
    "    best_weights_RES_path_ss4 = r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/models/UP_best_RES_3D_SS4_5_''' + str(index_iter + 1) + '.hdf5'\n",
    "\n",
    "    np.random.seed(seeds[index_iter])\n",
    "    #    train_indices, test_indices = sampleFixNum.samplingFixedNum(TRAIN_NUM, gt)\n",
    "    train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
    "\n",
    "    # TRAIN_SIZE = len(train_indices)\n",
    "    # print (TRAIN_SIZE)\n",
    "    #\n",
    "    # TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "    # print (TEST_SIZE)\n",
    "\n",
    "    y_train = gt[train_indices] - 1\n",
    "    y_train = to_categorical(np.asarray(y_train))\n",
    "\n",
    "    y_test = gt[test_indices] - 1\n",
    "    y_test = to_categorical(np.asarray(y_test))\n",
    "\n",
    "    # print (\"Validation data:\")\n",
    "    # collections.Counter(y_test_raw[-VAL_SIZE:])\n",
    "    # print (\"Testing data:\")\n",
    "    # collections.Counter(y_test_raw[:-VAL_SIZE])\n",
    "\n",
    "    train_assign = indexToAssignment(train_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
    "    for i in range(len(train_assign)):\n",
    "        train_data[i] = selectNeighboringPatch(padded_data, train_assign[i][0], train_assign[i][1], PATCH_LENGTH)\n",
    "\n",
    "    test_assign = indexToAssignment(test_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
    "    for i in range(len(test_assign)):\n",
    "        test_data[i] = selectNeighboringPatch(padded_data, test_assign[i][0], test_assign[i][1], PATCH_LENGTH)\n",
    "\n",
    "    x_train = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2], INPUT_DIMENSION_CONV)\n",
    "    x_test_all = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2], INPUT_DIMENSION_CONV)\n",
    "\n",
    "    x_val = x_test_all[-VAL_SIZE:]\n",
    "    y_val = y_test[-VAL_SIZE:]\n",
    "\n",
    "    x_test = x_test_all[:-VAL_SIZE]\n",
    "    y_test = y_test[:-VAL_SIZE]\n",
    "\n",
    "    # SS Residual Network 4 with BN\n",
    "    model_res4_SS_BN = res4_model_ss()\n",
    "\n",
    "    model_res4_SS_BN.load_weights(best_weights_RES_path_ss4)\n",
    "\n",
    "    pred_test_res4 = model_res4_SS_BN.predict(\n",
    "        x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1)).argmax(axis=1)\n",
    "    collections.Counter(pred_test_res4)\n",
    "    gt_test = gt[test_indices] - 1\n",
    "    overall_acc_res4 = metrics.accuracy_score(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    confusion_matrix_res4 = metrics.confusion_matrix(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    each_acc_res4, average_acc_res4 = averageAccuracy.AA_andEachClassAccuracy(confusion_matrix_res4)\n",
    "    kappa = metrics.cohen_kappa_score(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    KAPPA_RES_SS4.append(kappa)\n",
    "    OA_RES_SS4.append(overall_acc_res4)\n",
    "    AA_RES_SS4.append(average_acc_res4)\n",
    "    #TRAINING_TIME_RES_SS4.append(toc6 - tic6)\n",
    "    #TESTING_TIME_RES_SS4.append(toc7 - tic7)\n",
    "    ELEMENT_ACC_RES_SS4[index_iter, :] = each_acc_res4\n",
    "\n",
    "    print(\"3D RESNET_SS4 without BN training finished.\")\n",
    "    print(\"# %d Iteration\" % (index_iter + 1))\n",
    "\n",
    "    \n",
    "modelStatsRecord.outputStats_assess(KAPPA_RES_SS4, OA_RES_SS4, AA_RES_SS4, ELEMENT_ACC_RES_SS4, CATEGORY,\n",
    "                             r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/records/UP_test_SS_10.txt''',\n",
    "                             r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/records/UP_test_SS_element_10.txt''')\n",
    "\n",
    "print('Finished sampling in *Load UP* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
