{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished importing modules in *SSRN_ksc.py* at Fri May  3 00:19:10 2019\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.optimizers import Adam, SGD, Adadelta, RMSprop, Nadam\n",
    "import keras.callbacks as kcallbacks\n",
    "from keras.regularizers import l2\n",
    "import time\n",
    "import collections\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "from Utils import zeroPadding, normalization, doPCA, modelStatsRecord, averageAccuracy, ssrn_SS_ksc\n",
    "print('Finished importing modules in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished *indexToAssignment* modules in *SSRN_ksc.py* at Fri May  3 00:19:12 2019\n"
     ]
    }
   ],
   "source": [
    "def indexToAssignment(index_, Row, Col, pad_length):\n",
    "    new_assign = {}\n",
    "    for counter, value in enumerate(index_):\n",
    "        assign_0 = value // Col + pad_length\n",
    "        assign_1 = value % Col + pad_length\n",
    "        new_assign[counter] = [assign_0, assign_1]\n",
    "    return new_assign\n",
    "print('Finished *indexToAssignment* modules in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished *assignmentToIndex* in *SSRN_ksc.py* at Fri May  3 00:19:13 2019\n"
     ]
    }
   ],
   "source": [
    "def assignmentToIndex( assign_0, assign_1, Row, Col):\n",
    "    new_index = assign_0 * Col + assign_1\n",
    "    return new_index\n",
    "print('Finished *assignmentToIndex* in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished *selectNeighboringPatch* in *SSRN_ksc.py* at Fri May  3 00:19:14 2019\n"
     ]
    }
   ],
   "source": [
    "def selectNeighboringPatch(matrix, pos_row, pos_col, ex_len):\n",
    "    selected_rows = matrix[range(pos_row-ex_len,pos_row+ex_len+1), :]\n",
    "    selected_patch = selected_rows[:, range(pos_col-ex_len, pos_col+ex_len+1)]\n",
    "    return selected_patch\n",
    "print('Finished *selectNeighboringPatch* in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished *sampling* in *SSRN_ksc.py* at Fri May  3 00:19:16 2019\n"
     ]
    }
   ],
   "source": [
    "def sampling(proptionVal, groundTruth):              \n",
    "#divide dataset into train and test datasets\n",
    "    labels_loc = {}\n",
    "    train = {}\n",
    "    test = {}\n",
    "    m = max(groundTruth)\n",
    "    for i in range(m):\n",
    "        indices = [j for j, x in enumerate(groundTruth.ravel().tolist()) if x == i + 1]\n",
    "        np.random.shuffle(indices)\n",
    "        labels_loc[i] = indices\n",
    "        nb_val = int(proptionVal * len(indices))\n",
    "        train[i] = indices[:-nb_val]\n",
    "        test[i] = indices[-nb_val:]\n",
    "#    whole_indices = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for i in range(m):\n",
    "#        whole_indices += labels_loc[i]\n",
    "        train_indices += train[i]\n",
    "        test_indices += test[i]\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    return train_indices, test_indices\n",
    "print('Finished *sampling* in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished *res4modelss* in *SSRN_ksc.py* at Fri May  3 00:19:18 2019\n"
     ]
    }
   ],
   "source": [
    "def res4_model_ss():\n",
    "    model_res4 = ssrn_SS_ksc.ResnetBuilder.build_resnet_6((1, img_rows, img_cols, img_channels), nb_classes)\n",
    "\n",
    "    RMS = RMSprop(lr=0.0003)\n",
    "    # Let's train the model using RMSprop\n",
    "    model_res4.compile(loss='categorical_crossentropy', optimizer=RMS, metrics=['accuracy'])\n",
    "\n",
    "    return model_res4\n",
    "print('Finished *res4modelss* in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished module in *SSRN_ksc.py* at Fri May  3 00:19:19 2019\n"
     ]
    }
   ],
   "source": [
    "mat_data = sio.loadmat(r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/datasets/ksc/KSC.mat''',verify_compressed_data_integrity=False)\n",
    "data_ksc = mat_data['KSC']\n",
    "mat_gt = sio.loadmat(r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/datasets/ksc/ksc_gt.mat''')\n",
    "gt_ksc = mat_gt['KSC_gt']\n",
    "print('Finished module in *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Iteration\n",
      "input shape: 176\n",
      "input shape: (None, 7, 7, 85, 24)\n",
      "input shape: (None, 7, 7, 85, 24)\n",
      "conv_spc_result shape: (None, 7, 7, 1, 128)\n",
      "conv1 shape: (None, 5, 5, 1, 24)\n",
      "input shape: (None, 5, 5, 1, 24)\n",
      "input shape: (None, 5, 5, 1, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048, 7, 7, 176) (8176, 7, 7, 176)\n",
      "Train on 1048 samples, validate on 1025 samples\n",
      "Epoch 1/176\n",
      "1048/1048 [==============================] - 36s 34ms/step - loss: 2.0559 - acc: 0.3578 - val_loss: 3.0604 - val_acc: 0.0829\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.06037, saving model to C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/models/Indian_best_RES_3D_SS4_10_1.hdf5\n",
      "Epoch 2/176\n",
      "1048/1048 [==============================] - 28s 27ms/step - loss: 1.7161 - acc: 0.4599 - val_loss: 2.6205 - val_acc: 0.0829\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.06037 to 2.62046, saving model to C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/models/Indian_best_RES_3D_SS4_10_1.hdf5\n",
      "Epoch 3/176\n",
      "1048/1048 [==============================] - 29s 27ms/step - loss: 1.4732 - acc: 0.5458 - val_loss: 2.5937 - val_acc: 0.0917\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.62046 to 2.59372, saving model to C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/models/Indian_best_RES_3D_SS4_10_1.hdf5\n",
      "Epoch 4/176\n",
      "1048/1048 [==============================] - 30s 28ms/step - loss: 1.4214 - acc: 0.5620 - val_loss: 2.6198 - val_acc: 0.0829\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.59372\n",
      "Epoch 5/176\n",
      "1048/1048 [==============================] - 29s 28ms/step - loss: 1.2553 - acc: 0.6279 - val_loss: 2.6286 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.59372\n",
      "Epoch 6/176\n",
      "1048/1048 [==============================] - 30s 28ms/step - loss: 1.1998 - acc: 0.6298 - val_loss: 2.8327 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.59372\n",
      "Epoch 7/176\n",
      "1048/1048 [==============================] - 31s 29ms/step - loss: 1.1083 - acc: 0.6737 - val_loss: 2.8802 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.59372\n",
      "Epoch 8/176\n",
      "1048/1048 [==============================] - 33s 31ms/step - loss: 1.0359 - acc: 0.7252 - val_loss: 3.4695 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.59372\n",
      "Epoch 9/176\n",
      "1048/1048 [==============================] - 32s 31ms/step - loss: 0.9464 - acc: 0.7529 - val_loss: 3.8259 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.59372\n",
      "Epoch 10/176\n",
      "1048/1048 [==============================] - 33s 31ms/step - loss: 0.9145 - acc: 0.7739 - val_loss: 3.7340 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.59372\n",
      "Epoch 11/176\n",
      "1048/1048 [==============================] - 35s 33ms/step - loss: 0.9596 - acc: 0.7385 - val_loss: 4.1665 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.59372\n",
      "Epoch 12/176\n",
      "1048/1048 [==============================] - 36s 35ms/step - loss: 0.8389 - acc: 0.7786 - val_loss: 4.5743 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.59372\n",
      "Epoch 13/176\n",
      "1048/1048 [==============================] - 38s 36ms/step - loss: 0.8101 - acc: 0.8101 - val_loss: 4.9966 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.59372\n",
      "Epoch 14/176\n",
      "1048/1048 [==============================] - 36s 35ms/step - loss: 0.7813 - acc: 0.8034 - val_loss: 5.4290 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.59372\n",
      "Epoch 15/176\n",
      "1048/1048 [==============================] - 34s 32ms/step - loss: 0.7496 - acc: 0.7948 - val_loss: 6.0071 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.59372\n",
      "Epoch 16/176\n",
      "1048/1048 [==============================] - 34s 32ms/step - loss: 0.6942 - acc: 0.8292 - val_loss: 5.8622 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.59372\n",
      "Epoch 17/176\n",
      "1048/1048 [==============================] - 34s 32ms/step - loss: 0.6771 - acc: 0.8454 - val_loss: 6.7235 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.59372\n",
      "Epoch 18/176\n",
      "1048/1048 [==============================] - 34s 32ms/step - loss: 0.6646 - acc: 0.8311 - val_loss: 6.1409 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.59372\n",
      "Epoch 19/176\n",
      "1048/1048 [==============================] - 39s 38ms/step - loss: 0.6783 - acc: 0.8387 - val_loss: 6.4791 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.59372\n",
      "Epoch 20/176\n",
      "1048/1048 [==============================] - 41s 39ms/step - loss: 0.6466 - acc: 0.8349 - val_loss: 6.2312 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.59372\n",
      "Epoch 21/176\n",
      "1048/1048 [==============================] - 43s 41ms/step - loss: 0.5861 - acc: 0.8502 - val_loss: 7.0104 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.59372\n",
      "Epoch 22/176\n",
      "1048/1048 [==============================] - 42s 40ms/step - loss: 0.5971 - acc: 0.8426 - val_loss: 6.0332 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.59372\n",
      "Epoch 23/176\n",
      "1048/1048 [==============================] - 43s 41ms/step - loss: 0.5667 - acc: 0.8597 - val_loss: 6.2236 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.59372\n",
      "Epoch 24/176\n",
      "1048/1048 [==============================] - 42s 40ms/step - loss: 0.5387 - acc: 0.8721 - val_loss: 6.3146 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.59372\n",
      "Epoch 25/176\n",
      "1048/1048 [==============================] - 42s 41ms/step - loss: 0.5690 - acc: 0.8578 - val_loss: 5.9074 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.59372\n",
      "Epoch 26/176\n",
      "1048/1048 [==============================] - 43s 41ms/step - loss: 0.5449 - acc: 0.8597 - val_loss: 6.7192 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.59372\n",
      "Epoch 27/176\n",
      "1048/1048 [==============================] - 43s 41ms/step - loss: 0.5320 - acc: 0.8588 - val_loss: 7.0586 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.59372\n",
      "Epoch 28/176\n",
      "1048/1048 [==============================] - 42s 41ms/step - loss: 0.5156 - acc: 0.8807 - val_loss: 7.2704 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.59372\n",
      "Epoch 29/176\n",
      "1048/1048 [==============================] - 45s 43ms/step - loss: 0.5124 - acc: 0.8540 - val_loss: 6.7169 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.59372\n",
      "Epoch 30/176\n",
      "1048/1048 [==============================] - 44s 42ms/step - loss: 0.5018 - acc: 0.8674 - val_loss: 6.1940 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.59372\n",
      "Epoch 31/176\n",
      "1048/1048 [==============================] - 46s 44ms/step - loss: 0.5203 - acc: 0.8740 - val_loss: 6.6043 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.59372\n",
      "Epoch 32/176\n",
      "1048/1048 [==============================] - 45s 43ms/step - loss: 0.4677 - acc: 0.8865 - val_loss: 8.2231 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.59372\n",
      "Epoch 33/176\n",
      "1048/1048 [==============================] - 43s 41ms/step - loss: 0.4597 - acc: 0.8855 - val_loss: 7.6230 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.59372\n",
      "Epoch 34/176\n",
      "1048/1048 [==============================] - 32s 30ms/step - loss: 0.4601 - acc: 0.8855 - val_loss: 8.4041 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.59372\n",
      "Epoch 35/176\n",
      "1048/1048 [==============================] - 31s 30ms/step - loss: 0.4287 - acc: 0.8865 - val_loss: 7.4867 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.59372\n",
      "Epoch 36/176\n",
      "1048/1048 [==============================] - 32s 31ms/step - loss: 0.4201 - acc: 0.8845 - val_loss: 6.1821 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.59372\n",
      "Epoch 37/176\n",
      "1048/1048 [==============================] - 31s 30ms/step - loss: 0.4881 - acc: 0.8664 - val_loss: 7.6454 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.59372\n",
      "Epoch 38/176\n",
      "1048/1048 [==============================] - 32s 31ms/step - loss: 0.3945 - acc: 0.8998 - val_loss: 5.4088 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.59372\n",
      "Epoch 39/176\n",
      "1048/1048 [==============================] - 32s 30ms/step - loss: 0.4513 - acc: 0.8798 - val_loss: 6.5757 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.59372\n",
      "Epoch 40/176\n",
      "1048/1048 [==============================] - 32s 30ms/step - loss: 0.4135 - acc: 0.9008 - val_loss: 6.0617 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.59372\n",
      "Epoch 41/176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048/1048 [==============================] - 32s 31ms/step - loss: 0.4030 - acc: 0.9027 - val_loss: 5.7073 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.59372\n",
      "Epoch 42/176\n",
      " 975/1048 [==========================>...] - ETA: 1s - loss: 0.3960 - acc: 0.8933"
     ]
    }
   ],
   "source": [
    "#new_gt_IN = set_zeros(gt_IN, [1,4,7,9,13,15,16])\n",
    "new_gt_ksc = gt_ksc\n",
    "\n",
    "batch_size = 13\n",
    "nb_classes = 13\n",
    "nb_epoch = 176  #400\n",
    "img_rows, img_cols = 7, 7         #27, 27\n",
    "patience = 176\n",
    "\n",
    "INPUT_DIMENSION_CONV = 176\n",
    "INPUT_DIMENSION = 176\n",
    "TOTAL_SIZE = 10249\n",
    "VAL_SIZE = 1025\n",
    "\n",
    "TRAIN_SIZE = 1048\n",
    "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "VALIDATION_SPLIT = 0.8                      # 20% for trainnig and 80% for validation and testing\n",
    "# TRAIN_NUM = 10\n",
    "# TRAIN_SIZE = TRAIN_NUM * nb_classes\n",
    "# TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "# VAL_SIZE = TRAIN_SIZE\n",
    "img_channels = 176\n",
    "PATCH_LENGTH = 3                #Patch_size (13*2+1)*(13*2+1)\n",
    "\n",
    "data = data_ksc.reshape(np.prod(data_ksc.shape[:2]),np.prod(data_ksc.shape[2:]))\n",
    "gt = new_gt_ksc.reshape(np.prod(new_gt_ksc.shape[:2]),)\n",
    "\n",
    "data = preprocessing.scale(data)\n",
    "\n",
    "# scaler = preprocessing.MaxAbsScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "data_ = data.reshape(data_ksc.shape[0], data_ksc.shape[1],data_ksc.shape[2])\n",
    "whole_data = data_\n",
    "padded_data = zeroPadding.zeroPadding_3D(whole_data, PATCH_LENGTH)\n",
    "\n",
    "ITER = 1\n",
    "CATEGORY = 13\n",
    "\n",
    "train_data = np.zeros((TRAIN_SIZE, 2*PATCH_LENGTH + 1, 2*PATCH_LENGTH + 1, INPUT_DIMENSION_CONV))\n",
    "test_data = np.zeros((TEST_SIZE, 2*PATCH_LENGTH + 1, 2*PATCH_LENGTH + 1, INPUT_DIMENSION_CONV))\n",
    "\n",
    "KAPPA_RES_SS4 = []\n",
    "OA_RES_SS4 = []\n",
    "AA_RES_SS4 = []\n",
    "TRAINING_TIME_RES_SS4 = []\n",
    "TESTING_TIME_RES_SS4 = []\n",
    "ELEMENT_ACC_RES_SS4 = np.zeros((ITER, CATEGORY))\n",
    "\n",
    "#seeds = [1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229]\n",
    "\n",
    "seeds = [1334]\n",
    "\n",
    "for index_iter in range(ITER):\n",
    "    print(\"# %d Iteration\" % (index_iter + 1))\n",
    "\n",
    "    # save the best validated model \n",
    "    \n",
    "    best_weights_RES_path_ss4 = r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/models/Indian_best_RES_3D_SS4_10_''' + str(\n",
    "        index_iter + 1) + '.hdf5'\n",
    "\n",
    "    np.random.seed(seeds[index_iter])\n",
    "#    train_indices, test_indices = sampleFixNum.samplingFixedNum(TRAIN_NUM, gt)\n",
    "    train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
    "\n",
    "    # TRAIN_SIZE = len(train_indices)\n",
    "    # print (TRAIN_SIZE)\n",
    "    #\n",
    "    # TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "    # print (TEST_SIZE)\n",
    "\n",
    "    y_train = gt[train_indices] - 1\n",
    "    y_train = to_categorical(np.asarray(y_train))\n",
    "\n",
    "    y_test = gt[test_indices] - 1\n",
    "    y_test = to_categorical(np.asarray(y_test))\n",
    "\n",
    "    # print (\"Validation data:\")\n",
    "    # collections.Counter(y_test_raw[-VAL_SIZE:])\n",
    "    # print (\"Testing data:\")\n",
    "    # collections.Counter(y_test_raw[:-VAL_SIZE])\n",
    "\n",
    "    train_assign = indexToAssignment(train_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
    "    for i in range(len(train_assign)):\n",
    "        train_data[i] = selectNeighboringPatch(padded_data, train_assign[i][0], train_assign[i][1], PATCH_LENGTH)\n",
    "\n",
    "    test_assign = indexToAssignment(test_indices, whole_data.shape[0], whole_data.shape[1], PATCH_LENGTH)\n",
    "    for i in range(len(test_assign)):\n",
    "        test_data[i] = selectNeighboringPatch(padded_data, test_assign[i][0], test_assign[i][1], PATCH_LENGTH)\n",
    "\n",
    "    x_train = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2], INPUT_DIMENSION_CONV)\n",
    "    x_test_all = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2], INPUT_DIMENSION_CONV)\n",
    "\n",
    "    x_val = x_test_all[-VAL_SIZE:]\n",
    "    y_val = y_test[-VAL_SIZE:]\n",
    "\n",
    "    x_test = x_test_all[:-VAL_SIZE]\n",
    "    y_test = y_test[:-VAL_SIZE]\n",
    "\n",
    "    # SS Residual Network 4 with BN\n",
    "    model_res4_SS_BN = res4_model_ss()\n",
    "\n",
    "    earlyStopping6 = kcallbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "    saveBestModel6 = kcallbacks.ModelCheckpoint(best_weights_RES_path_ss4, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    tic6 = time.clock()\n",
    "\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    history_res4_SS_BN = model_res4_SS_BN.fit(x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3], 1), y_train, validation_data=(x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], x_val.shape[3], 1), y_val), batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, callbacks=[earlyStopping6, saveBestModel6])\n",
    "    toc6 = time.clock()\n",
    "\n",
    "    tic7 = time.clock()\n",
    "    loss_and_metrics_res4_SS_BN = model_res4_SS_BN.evaluate(x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1), y_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1), batch_size=batch_size)\n",
    "    toc7 = time.clock()\n",
    "\n",
    "    print('3D RES_SS4 without BN Training Time: ', toc6 - tic6)\n",
    "    print('3D RES_SS4 without BN Test time:', toc7 - tic7)\n",
    "\n",
    "    print('3D RES_SS4 without BN Test score:', loss_and_metrics_res4_SS_BN[0])\n",
    "    print('3D RES_SS4 without BN Test accuracy:', loss_and_metrics_res4_SS_BN[1])\n",
    "\n",
    "    print(history_res4_SS_BN.history.keys())\n",
    "\n",
    "    pred_test_res4 = model_res4_SS_BN.predict(x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1)).argmax(axis=1)\n",
    "    collections.Counter(pred_test_res4)\n",
    "    gt_test = gt[test_indices] - 1\n",
    "    overall_acc_res4 = metrics.accuracy_score(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    confusion_matrix_res4 = metrics.confusion_matrix(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    each_acc_res4, average_acc_res4 = averageAccuracy.AA_andEachClassAccuracy(confusion_matrix_res4)\n",
    "    kappa = metrics.cohen_kappa_score(pred_test_res4, gt_test[:-VAL_SIZE])\n",
    "    KAPPA_RES_SS4.append(kappa)\n",
    "    OA_RES_SS4.append(overall_acc_res4)\n",
    "    AA_RES_SS4.append(average_acc_res4)\n",
    "    TRAINING_TIME_RES_SS4.append(toc6 - tic6)\n",
    "    TESTING_TIME_RES_SS4.append(toc7 - tic7)\n",
    "    ELEMENT_ACC_RES_SS4[index_iter, :] = each_acc_res4\n",
    "\n",
    "    print(\"3D RESNET_SS4 without BN training finished.\")\n",
    "    print(\"# %d Iteration\" % (index_iter + 1))\n",
    "\n",
    "modelStatsRecord.outputStats(KAPPA_RES_SS4, OA_RES_SS4, AA_RES_SS4, ELEMENT_ACC_RES_SS4,\n",
    "                             TRAINING_TIME_RES_SS4, TESTING_TIME_RES_SS4,\n",
    "                             history_res4_SS_BN, loss_and_metrics_res4_SS_BN, CATEGORY,\n",
    "                             r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/records/ksc_train_SS_10.txt''',\n",
    "                             r'''C:/Users/josep/Desktop/RS/residualnet_tensorflow_keras/residualnet_tensorflow_keras/SSRN-master/records/ksc_train_SS_element_10.txt''')\n",
    "\n",
    "print('Finished running *SSRN_ksc.py* at ' + time.ctime(time.time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
